# Latent Dirichlet Allocation

## What is Latent Dirichlet Allocation and Non-Negative Matrix Factorization?

As mentioned [here](https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730):

LDA is an algorithm that is used to discover the topics that are in a text. Topic modelling is an unsupervised model for detecting topics in a corpus and categorizing similar texts. Assume that you have some documents, for example Government Gazette Documents, and you want to cluster them to similar topics. Then LDA or NMF or  is a way to go. The mathematical basis underpinning NMF is quite different from LDA. We are going to use sklearn for topic modelling and clustering to similar topics. 

The code is located at `src/lda.py` 



```
{0: [23, 10], 1: [28, 26], 3: [25, 15], 5: [13, 35], 6: [9, 16], 8: [34, 36], 9: [6, 16], 10: [17, 36], 12: [29, 30], 13: [5, 35], 15: [25, 3], 16: [6, 9], 17: [10, 36], 19: [8, 33], 20: [36, 25], 23: [0, 10], 25: [3, 15], 26: [1, 28], 28: [1, 26], 29: [12, 30], 30: [12, 29], 33: [8, 19], 34: [36, 8], 35: [13, 5], 36: [17, 10]}
{0: ['παρ', 'εξής', '2016', '2017', 'υπουργού'], 1: ['τροποποιείται', 'πρόσωπο', '2001', 'επωνυμία', 'υποχρεώσεις'], 2: ['κορέας', 'λαϊκή', 'δημοκρατία', 'λαϊκής', 'δημοκρατίας'], 3: ['36', '27', 'περιοχή', 'διατάγματος', 'πρώτο'], 4: ['πράξης', 'φράση', '24', '11', '12'], 5: ['τμήμα', 'ακτ', 'ελ', 'πε', 'διεύθυνση'], 6: ['διατάγματος', 'υπουργό', 'δημοσίευση', 'αρχίζει', 'αθήνα'], 7: ['αστυνομίας', 'ελληνικής', 'αξιωματικοί', 'εξής', 'αστυνομικού'], 8: ['πακέτου', 'διοργανωτής', 'ταξιδιού', 'πακέτο', 'οργανωμένου'], 9: ['ενέργειας', 'θερμικής', 'ηλεκτρικής', 'παραγωγής', 'διανομής']}
Topic 0:
τμήμα πε παρ διεύθυνση διεύθυνσης
13.txt
16.txt
27.txt
Topic 1:
κεφαλαιαγοράς επιτροπή εε 2014 εξής
15.txt
11.txt
34.txt
Topic 2:
ελ ακτ πολιτικής τμήμα διεύθυνση
4.txt
13.txt
12.txt
Topic 3:
ακτ ελ πολιτικής παρ τμήμα
13.txt
16.txt
27.txt
Topic 4:
παρ τμήμα υπουργείου εξής ελ
13.txt
16.txt
27.txt
Topic 5:
κορέας λαϊκή δημοκρατία δημοκρατίας λαϊκής
8.txt
18.txt
32.txt
Topic 6:
τμήμα παρ επιτροπή κεφαλαιαγοράς γενικής
13.txt
16.txt
27.txt
Topic 7:
παρ τμήμα διεύθυνση εξής υπουργείου
13.txt
16.txt
27.txt
Topic 8:
τμήμα πε αρχαιοτήτων μνημείων αθλητισμού
20.txt
10.txt
30.txt
Topic 9:
παρ εξής ενέργειας φορέα 2016
3.txt
25.txt
36.txt
{1: [18, 22], 2: [13, 5], 4: [18, 24], 5: [2, 13], 10: [17, 16], 12: [30, 29], 13: [2, 5], 15: [28, 26], 16: [10, 17], 17: [10, 16], 18: [24, 4], 22: [1, 18], 24: [18, 4], 26: [28, 15], 28: [15, 26], 29: [30, 12], 30: [12, 29]}
{0: ['τμήμα', 'πε', 'παρ', 'διεύθυνση', 'διεύθυνσης'], 1: ['κεφαλαιαγοράς', 'επιτροπή', 'εε', '2014', 'εξής'], 2: ['ελ', 'ακτ', 'πολιτικής', 'τμήμα', 'διεύθυνση'], 3: ['ακτ', 'ελ', 'πολιτικής', 'παρ', 'τμήμα'], 4: ['παρ', 'τμήμα', 'υπουργείου', 'εξής', 'ελ'], 5: ['κορέας', 'λαϊκή', 'δημοκρατία', 'δημοκρατίας', 'λαϊκής'], 6: ['τμήμα', 'παρ', 'επιτροπή', 'κεφαλαιαγοράς', 'γενικής'], 7: ['παρ', 'τμήμα', 'διεύθυνση', 'εξής', 'υπουργείου'], 8: ['τμήμα', 'πε', 'αρχαιοτήτων', 'μνημείων', 'αθλητισμού'], 9: ['παρ', 'εξής', 'ενέργειας', 'φορέα', '2016']}
Breadth first Search for Connected Components for NMF
[[0, 23, 10, 17, 36], [1, 28, 26], [3, 25, 15], [5, 13, 35], [6, 9, 16], [8, 34], [12, 29, 30], [19, 33], [20]]

Breadth first Search for Connected Components for Latent Dirichlet Allocation
[[0, 23, 10, 17, 36], [1, 28, 26], [3, 25, 15], [5, 13, 35], [6, 9, 16], [8, 34], [12, 29, 30], [19, 33], [20]]
```